# To run this code you need to install the following dependencies:
# pip install google-genai

import base64
import os
import time
import sys
from google import genai
from google.genai import types
from dotenv import load_dotenv

from src.prompts.ocr_prompt import get_input_prompt
from src.utils.files import read_file, write_file, load_pdf_data
from src.utils.formater import clean_json_content

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

load_dotenv()

def generate():
    # Start timing
    start_time = time.time()
    print(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω PDF l√∫c: {time.strftime('%H:%M:%S', time.localtime(start_time))}")
    
    client = genai.Client(
        api_key=os.getenv("GEMINI_API_KEY"),
    )

    model = "gemini-2.5-flash"

    # Time: Loading files
    load_start = time.time()
    json_format = read_file("./financial_metrics/metrics.json")
    
    # Load PDF data (base64 encoded)
    pdf_data = load_pdf_data("./docs/poor_2.pdf")
    load_time = time.time() - load_start
    print(f"Th·ªùi gian load files: {load_time:.2f} gi√¢y")
    
    # Time: Preparing content
    prep_start = time.time()
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text=get_input_prompt(json_format)),
                types.Part.from_bytes(
                    data=base64.b64decode(pdf_data),
                    mime_type="application/pdf"
                ),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )
    prep_time = time.time() - prep_start
    print(f"Th·ªùi gian chu·∫©n b·ªã: {prep_time:.2f} gi√¢y")

    # Time: AI Processing
    ai_start = time.time()
    print("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω v·ªõi Gemini AI...")

    # Collect all chunks before writing to file
    full_response = ""
    chunk_count = 0
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        # Handle None values in streaming chunks
        if chunk.text is not None:
            print(chunk.text, end="")
            full_response += chunk.text
            chunk_count += 1
        else:
            print("\nG·∫∑p chunk kh√¥ng c√≥ text, d·ª´ng stream")
            break
    
    ai_time = time.time() - ai_start
    print(f"\nTh·ªùi gian AI x·ª≠ l√Ω: {ai_time:.2f} gi√¢y ({chunk_count} chunks)")
    
    # Time: Post-processing
    post_start = time.time()
    print("ƒêang l√†m s·∫°ch v√† l∆∞u JSON...")
    
    # Clean and format JSON before writing to file
    cleaned_json = clean_json_content(full_response)
    output_filename = f"./output/output_{int(time.time())}.json"
    write_file(output_filename, cleaned_json)
    
    post_time = time.time() - post_start
    total_time = time.time() - start_time
    
    # Summary
    print(f"\nüìä T·ªîNG K·∫æT TH·ªúI GIAN:")
    print(f"‚îú‚îÄ‚îÄ Load files: {load_time:.2f}s")
    print(f"‚îú‚îÄ‚îÄ Chu·∫©n b·ªã: {prep_time:.2f}s") 
    print(f"‚îú‚îÄ‚îÄ AI x·ª≠ l√Ω: {ai_time:.2f}s ({ai_time/total_time*100:.1f}%)")
    print(f"‚îú‚îÄ‚îÄ H·∫≠u x·ª≠ l√Ω: {post_time:.2f}s")
    print(f"‚îî‚îÄ‚îÄ T·ªîNG C·ªòNG: {total_time:.2f}s")
    print(f"\n‚úÖ Ho√†n th√†nh! File l∆∞u t·∫°i: {output_filename}")
    
    return total_time


if __name__ == "__main__":
    try:
        total_time = generate()
        print(f"\nüéØ K·∫øt th√∫c x·ª≠ l√Ω th√†nh c√¥ng trong {total_time:.2f} gi√¢y")
    except Exception as e:
        print(f"\n‚ùå L·ªói x·∫£y ra: {e}")
        raise